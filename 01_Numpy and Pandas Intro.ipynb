{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why python for data analysis, machine learning?\n",
    "There are lots of reasons that we want to use python for doing data science. It is certainly one of the younger programming languages used in the data science ecosystem (compared to say R and SAS) but it is used just as frequently for analysis as SAS and R. Having a good foundation in python and R, (and SAS or SPSS) should be a *must* for **every data scientist** and machine learning enthusiast. \n",
    "\n",
    "Here is a latex equation $\\lambda=5$ \n",
    "\n",
    "In this course, python allows for an open source method of performing machine learning that runs from just about any machine. So let's start with looking at Numpy and Pandas pachages for analyzing data. \n",
    "\n",
    "With that in mind, let's go over the following:\n",
    "- Numpy matrices\n",
    "- Simple operations on arrays and matrices\n",
    "- Indexing with numpy\n",
    "- Pandas for tabular data\n",
    "- Representing categorical data (discussion point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.16 (default, Mar  1 2023, 21:18:45) \n",
      "[Clang 14.0.6 ]\n",
      "1.23.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "print(sys.version)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89162028, 0.97369146, 0.84477866],\n",
       "       [0.82200745, 0.04894302, 0.34575096],\n",
       "       [0.96169398, 0.22250412, 0.94717825],\n",
       "       [0.85062942, 0.64487153, 0.1689844 ],\n",
       "       [0.27999124, 0.78141442, 0.05305638]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,3) (3,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# will this work?\u001b[39;00m\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43my\u001b[49m\n\u001b[1;32m      4\u001b[0m z\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,3) (3,4) "
     ]
    }
   ],
   "source": [
    "# will this work?\n",
    "y = np.random.rand(3,4)\n",
    "z = x*y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.62519216, 1.61165567, 2.0642909 , 1.47188586],\n",
       "       [0.81208096, 1.00549686, 0.82198292, 0.44786103],\n",
       "       [1.52738965, 1.53879288, 1.44356732, 0.99309143],\n",
       "       [0.84452074, 1.08814595, 1.31620868, 0.78637785],\n",
       "       [0.45454204, 0.50838927, 0.98475922, 0.68175702]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can designate what matrix multiplication is directly using objects\n",
    "z = np.dot(x,y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.62519216, 1.61165567, 2.0642909 , 1.47188586],\n",
       "       [0.81208096, 1.00549686, 0.82198292, 0.44786103],\n",
       "       [1.52738965, 1.53879288, 1.44356732, 0.99309143],\n",
       "       [0.84452074, 1.08814595, 1.31620868, 0.78637785],\n",
       "       [0.45454204, 0.50838927, 0.98475922, 0.68175702]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or we can use the overloaded matrix multiplication operator\n",
    "z = x @ y\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([[1,2,3],\n",
    "               [4,5,6],\n",
    "               [7,8,9]])\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(x1.shape[0]):\n",
    "    print(x1[row,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x1[:,1])\n",
    "print(x1[:,1]>3)\n",
    "# slicing\n",
    "print(x1[ x1[:,1]>3 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.array(range(10))\n",
    "print(x2)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = x2>5\n",
    "print(idx)\n",
    "print(x2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[x2>5] # rows of x2 where x2 is greater than 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named columns\n",
    "So what if we have a matrix of data where each row is some observation of features and the feature values are represented in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['temperature','time','day']\n",
    "data = np.array([[64,2100,1],\n",
    "                 [50,2200,4],\n",
    "                 [48,2300,3],\n",
    "                 [34,0,   2],\n",
    "                 [30,100, 5]])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data[:,1]>1500]\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas to the rescue\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "\n",
    "df = pd.DataFrame(data,columns=col_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can always access the backend numpy with .values\n",
    "print(type(df.to_numpy()))\n",
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.time>1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get a description of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.day[df.day==1] = 'Mon'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is almost always a more efficient built in pandas function\n",
    "df.day.replace(to_replace=range(7),\n",
    "               value=['Su','Mon','Tues','Wed','Th','Fri','Sat'],\n",
    "               inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice how the type of the column has changed to an object \"categorical\"\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding example\n",
    "pd.get_dummies(df.day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Pandas Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing into a pandas dataframe\n",
    "print(df.day)\n",
    "print(df['day'])\n",
    "df[['day','temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.day[2]) # print the value\n",
    "print(df.day[2:]) # print as pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index location\n",
    "df.iloc[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3:][['day','temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['day','temperature']].iloc[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(numeric_only=True)/df.std(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.time.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Block Manager\n",
    "Let's take a look at some important points from the following post:\n",
    " - https://uwekorn.com/2020/05/24/the-one-pandas-internal.html\n",
    "\n",
    "This is the pandas BlockManager, which tries to group internal structures together to make things fast:\n",
    "<img src=\"https://uwekorn.com/images/pd-df-perception.002.png\" width=200 height=200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df._data.nblocks)\n",
    "df._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and disadvantages:\n",
    "This can speed up operations because it inhenertly can apply operations along columns in a single pass over the data (like sums, etc.) and therefore is using c++ for much of the heavy lifting.\n",
    "\n",
    "But, **it might be bad** when you are adding columns to the data because it can trigger consolidation of columns, which means copying over data in numpy to creata new matrix. The slow down also doesn't show up until a needed column is accessed (lazy data copying). Let's do an example from:  https://uwekorn.com/2020/05/24/the-one-pandas-internal.html\n",
    "\n",
    "**Block consolidation is triggered after 100 blocks of data are reached.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will start with a 2 column dataframe\n",
    "# one column is an int and the other a float\n",
    "# becasue there are two datatypes this has two blocks\n",
    "df_example = pd.DataFrame({\n",
    "    'int64': np.arange(1024 * 1024, dtype=np.int64),\n",
    "    'float64': np.arange(1024 * 1024, dtype=np.float64),\n",
    "})\n",
    "df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# but now lets start to add columns one by one\n",
    "# to be fast, pandas adds each as a new block \n",
    "# so we will have 99 blocks (2+97 new ones)\n",
    "for i in range(96):\n",
    "    df_example[f'new_{i}'] = df_example['int64'].to_numpy()\n",
    "    \n",
    "print(df_example._data.nblocks)\n",
    "df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_example['dummy_name5'] = df_example['int64'].to_numpy() # copy over some new columns\n",
    "print('Number of blocks in data:',df_example._data.nblocks)\n",
    "\n",
    "# force consolidation \n",
    "%time df_example = df_example.reindex()\n",
    "\n",
    "%time df_example['dummy_name6'] = df_example['int64'].to_numpy() # copy over some new columns\n",
    "print('Number of blocks in data:',df_example._data.nblocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_example.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
