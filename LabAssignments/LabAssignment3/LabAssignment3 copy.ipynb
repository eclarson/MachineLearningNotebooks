{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Three: Extending Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "- Juliana Antonio\n",
    "- Xiaona Hang\n",
    "- Chuanqi Deng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparation and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Body Performance Data\" sourced from the [Korea Sports Promotion Foundation](https://www.bigdata-culture.kr/bigdata/user/data_market/detail.do?id=ace0aea7-5eee-48b9-b616-637365d665c1), available on Kaggle, comprises 13,393 rows and encompasses 12 features, such as age, gender, height, weight, and more. This dataset, meticulously curated, demonstrates the correlation between age and various exercise performance metrics, thereby providing insights into individual performance grades.\n",
    "\n",
    "Utilizing this rich dataset, the aim is to classify individuals into distinct performance grades: A (Best), B, C, and D (Worst), based on the aforementioned 12 features. This classification is pivotal for tailoring personalized training plans, catering to diverse needs and abilities. Consequently, gyms and rehabilitation centers stand to benefit significantly from leveraging predictive analytics to craft bespoke training plans, optimizing clients' progress and well-being.\n",
    "\n",
    "Beyond professional institutions, individuals themselves will be interested in understanding their body performance classification. Armed with this knowledge, they can make informed decisions regarding their fitness journey, setting realistic goals and embracing tailored approaches for holistic improvement.\n",
    "\n",
    "The deployment of a robust classification model is expected to achieve an accuracy of approximately 80%. By meeting this benchmark, the model ensures reliable predictions, empowering stakeholders to make data-driven decisions with confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13393, 12), (13393, 8))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "raw_data = pd.read_csv(\"data/bodyPerformance.csv\")\n",
    "\n",
    "# preprocessing\n",
    "data = pd.get_dummies(raw_data, columns=['gender'],dtype=np.int8) # one-hot encoding for gender\n",
    "labels = data['class'].map(lambda c: ord(c) - ord('A')) # encode lables into integer\n",
    "data.drop(['class'], axis=1, inplace=True) # remove class column\n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(data)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(8)\n",
    "pca_feature = pca.fit_transform(features)\n",
    "raw_data.shape, pca_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has one categorical feature, the gender. One-hot encoding is enployed to convert it into numerical data. Next, the lables/class is moved to another separate variable, lables. Then, the Standard Scaling and PCA are applied to mitigate the difference of multiple features reduce the number of features from 12 to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.339300e+04</td>\n",
       "      <td>1.339300e+04</td>\n",
       "      <td>1.339300e+04</td>\n",
       "      <td>1.339300e+04</td>\n",
       "      <td>1.339300e+04</td>\n",
       "      <td>1.339300e+04</td>\n",
       "      <td>1.339300e+04</td>\n",
       "      <td>1.339300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.283724e-16</td>\n",
       "      <td>-7.709306e-19</td>\n",
       "      <td>-2.368747e-17</td>\n",
       "      <td>-4.912403e-17</td>\n",
       "      <td>-2.337661e-18</td>\n",
       "      <td>2.952747e-17</td>\n",
       "      <td>-1.345398e-17</td>\n",
       "      <td>5.760945e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.386378e+00</td>\n",
       "      <td>1.462662e+00</td>\n",
       "      <td>1.127011e+00</td>\n",
       "      <td>9.438121e-01</td>\n",
       "      <td>8.081770e-01</td>\n",
       "      <td>5.785046e-01</td>\n",
       "      <td>5.602344e-01</td>\n",
       "      <td>4.860709e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.041796e+00</td>\n",
       "      <td>-5.384663e+00</td>\n",
       "      <td>-7.437324e+00</td>\n",
       "      <td>-4.140902e+00</td>\n",
       "      <td>-4.012083e+00</td>\n",
       "      <td>-2.242237e+00</td>\n",
       "      <td>-5.062883e+00</td>\n",
       "      <td>-2.246422e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.967484e+00</td>\n",
       "      <td>-1.012307e+00</td>\n",
       "      <td>-6.911124e-01</td>\n",
       "      <td>-6.042082e-01</td>\n",
       "      <td>-4.971976e-01</td>\n",
       "      <td>-3.845767e-01</td>\n",
       "      <td>-3.517389e-01</td>\n",
       "      <td>-3.142285e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-8.995369e-01</td>\n",
       "      <td>1.073930e-01</td>\n",
       "      <td>5.143689e-02</td>\n",
       "      <td>1.506179e-02</td>\n",
       "      <td>7.247022e-03</td>\n",
       "      <td>1.665698e-02</td>\n",
       "      <td>8.867419e-03</td>\n",
       "      <td>-3.037003e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.360703e+00</td>\n",
       "      <td>1.072822e+00</td>\n",
       "      <td>7.628835e-01</td>\n",
       "      <td>6.133066e-01</td>\n",
       "      <td>5.253231e-01</td>\n",
       "      <td>3.905508e-01</td>\n",
       "      <td>3.792356e-01</td>\n",
       "      <td>3.000243e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.506510e+00</td>\n",
       "      <td>7.782459e+00</td>\n",
       "      <td>1.473913e+01</td>\n",
       "      <td>4.345014e+00</td>\n",
       "      <td>1.360873e+01</td>\n",
       "      <td>3.636507e+00</td>\n",
       "      <td>5.873632e+00</td>\n",
       "      <td>6.967697e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  1.339300e+04  1.339300e+04  1.339300e+04  1.339300e+04  1.339300e+04   \n",
       "mean  -1.283724e-16 -7.709306e-19 -2.368747e-17 -4.912403e-17 -2.337661e-18   \n",
       "std    2.386378e+00  1.462662e+00  1.127011e+00  9.438121e-01  8.081770e-01   \n",
       "min   -5.041796e+00 -5.384663e+00 -7.437324e+00 -4.140902e+00 -4.012083e+00   \n",
       "25%   -1.967484e+00 -1.012307e+00 -6.911124e-01 -6.042082e-01 -4.971976e-01   \n",
       "50%   -8.995369e-01  1.073930e-01  5.143689e-02  1.506179e-02  7.247022e-03   \n",
       "75%    2.360703e+00  1.072822e+00  7.628835e-01  6.133066e-01  5.253231e-01   \n",
       "max    6.506510e+00  7.782459e+00  1.473913e+01  4.345014e+00  1.360873e+01   \n",
       "\n",
       "                  5             6             7  \n",
       "count  1.339300e+04  1.339300e+04  1.339300e+04  \n",
       "mean   2.952747e-17 -1.345398e-17  5.760945e-17  \n",
       "std    5.785046e-01  5.602344e-01  4.860709e-01  \n",
       "min   -2.242237e+00 -5.062883e+00 -2.246422e+00  \n",
       "25%   -3.845767e-01 -3.517389e-01 -3.142285e-01  \n",
       "50%    1.665698e-02  8.867419e-03 -3.037003e-03  \n",
       "75%    3.905508e-01  3.792356e-01  3.000243e-01  \n",
       "max    3.636507e+00  5.873632e+00  6.967697e+00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# breakdown of the variables\n",
    "pd.DataFrame(pca_feature).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [07:52<00:00, 59.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# test different folds of cross validation\n",
    "cross_validation_accs = {}\n",
    "# n fold cross-validation, n: 3-10\n",
    "for n in tqdm(range(3, 11)):\n",
    "    # n-fold cross-validation\n",
    "    cross_validator = KFold(n_splits=n)\n",
    "    split_indices = cross_validator.split(pca_feature, labels)\n",
    "    \n",
    "    # training and testing\n",
    "    avg_accs = []\n",
    "    for train_indices, test_indices in split_indices:\n",
    "        X_train, y_train = pca_feature[train_indices], labels[train_indices]\n",
    "        X_test, y_test = pca_feature[test_indices], labels[test_indices]\n",
    "        \n",
    "        classifier = SVC()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        avg_accs.append(acc)\n",
    "    \n",
    "    cross_validation_accs[n] = avg_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cross Validation Accuracies')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cross validation accuracies\n",
    "plt.boxplot(cross_validation_accs.values(), labels=list(range(3, 11)))\n",
    "ax = plt.twiny()\n",
    "avg_accs = [np.mean(accs) for accs in cross_validation_accs.values()]\n",
    "ax.plot(avg_accs, label='mean accuracies')\n",
    "ax.set_axis_off()\n",
    "ax.legend(loc = 'upper left')\n",
    "plt.title(\"Cross Validation Accuracies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the graph above, it is clear that the 7-fold cross-validation has the best accuracies, considering the stablity and median accuracy. Hence, a rougly 86/14 split would be ideal for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the optimal number of folds for the following analysis\n",
    "cross_validator = KFold(n_splits=7)\n",
    "split_indices = cross_validator.split(pca_feature, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Modeling** \n",
    "\n",
    "The implementation of logistic regression must be written only from the examples given to you by the instructor. No credit will be assigned to teams that copy implementations from another source, regardless of if the code is properly cited. \n",
    "\n",
    "2.1 \n",
    "\n",
    "Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template developed by the instructor in the course. You should add the following functionality to the logistic regression classifier:\n",
    "Ability to choose optimization technique when class is instantiated: either steepest ascent, stochastic gradient ascent, and Newton's method. It is recommended to call this the \"solver\" input for the class.\n",
    "\n",
    "Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1 and L2 regularization). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  \n",
    "\n",
    "2.2\n",
    "\n",
    "Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term(s) \"C\" to achieve the best performance on your test set. Visualize the performance of the classifier versus the parameters you investigated.\n",
    "Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1  Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Binary Logistic Regression Object, Not Trainable\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "\n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta))\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_intercept(X):\n",
    "        return np.hstack((np.ones((X.shape[0], 1)), X))  # add bias term\n",
    "\n",
    "    # public:\n",
    "    def predict_proba(self, X, add_intercept=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_intercept(X) if add_intercept else X\n",
    "        return self._sigmoid(Xb @ self.w_)  # return the probability y=1\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) > 0.5)  # return the actual prediction\n",
    "\n",
    "\n",
    "blr = BinaryLogisticRegressionBase(0.1)\n",
    "print(blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained Binary Logistic Regression Object\n"
     ]
    }
   ],
   "source": [
    "# inherit from base class\n",
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    # private:\n",
    "    def __str__(self):\n",
    "        if (hasattr(self, 'w_')):\n",
    "            # is we have trained the object\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n' + str(self.w_)\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "\n",
    "    def _get_gradient(self, X, y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape)  # set gradient to zero\n",
    "        for (xi, yi) in zip(X, y):\n",
    "            # the actual update inside of sum\n",
    "            gradi = (yi - self.predict_proba(xi, add_intercept=False))*xi\n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape)\n",
    "\n",
    "        return gradient/float(len(y))\n",
    "\n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_intercept(X)  # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "\n",
    "        self.w_ = np.zeros((num_features, 1))  # init weight vector to zeros\n",
    "\n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb, y)\n",
    "            self.w_ += gradient*self.eta  # multiply by learning rate\n",
    "\n",
    "\n",
    "blr = BinaryLogisticRegression(0.1)\n",
    "print(blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Regression Object with coefficients:\n",
      "[[-0.00029092]\n",
      " [ 0.04395626]\n",
      " [-0.22565824]\n",
      " [-0.248578  ]\n",
      " [ 0.10309809]\n",
      " [-0.07139034]\n",
      " [-0.0323019 ]\n",
      " [ 0.00401275]\n",
      " [ 0.05577395]]\n",
      "Accuracy of:  0.7841087297438578\n"
     ]
    }
   ],
   "source": [
    "# train the classifier with the optimal number of folds and the pca data\n",
    "for train_indices, test_indices in split_indices:\n",
    "    X_train, y_train = pca_feature[train_indices], ((labels[train_indices]) > 1)\n",
    "    X_test, y_test = pca_feature[test_indices], ((labels[test_indices]) > 1)\n",
    "\n",
    "# train the classifier with the pca data\n",
    "# X = pca_feature\n",
    "# Y = labels > 1\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train the classifier\n",
    "blr = BinaryLogisticRegression(eta=0.1, iterations=12)\n",
    "blr.fit(X_train, y_train)\n",
    "print(blr)\n",
    "\n",
    "yhat = blr.predict(X_test)\n",
    "print('Accuracy of: ', accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Regression Object with coefficients:\n",
      "[[ 0.01174409]\n",
      " [ 0.06053577]\n",
      " [-0.49916394]\n",
      " [-0.68773908]\n",
      " [ 0.32374941]\n",
      " [-0.24576778]\n",
      " [-0.11727782]\n",
      " [ 0.01352371]\n",
      " [ 0.20394337]]\n",
      "Accuracy of:  0.8008363826450601\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier with more iterations to check if the accuracy improves\n",
    "params = dict(eta=0.01,\n",
    "              iterations=500)\n",
    "\n",
    "blr = BinaryLogisticRegression(**params)\n",
    "blr.fit(X_train,y_train)\n",
    "print(blr)\n",
    "yhat = blr.predict(X_test)\n",
    "print('Accuracy of: ',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use numpy and scipy expit to optimize the Logistic Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seren\\AppData\\Local\\Temp\\ipykernel_15296\\1043485029.py:17: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  gradient = np.mean(X * ydiff[:, np.newaxis], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01711285]\n",
      " [ 0.06151229]\n",
      " [-0.50023012]\n",
      " [-0.68692673]\n",
      " [ 0.32376052]\n",
      " [-0.24934156]\n",
      " [-0.12075615]\n",
      " [ 0.0245485 ]\n",
      " [ 0.2028872 ]]\n",
      "Accuracy of Vectorized Programing for Regression:  0.799552071668533\n"
     ]
    }
   ],
   "source": [
    "# Vectorized Programming for Logistic Regression\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability using expit which is more stable\n",
    "        return expit(theta)  # 1/(1+np.exp(-theta))\n",
    "\n",
    "    # overwrite the gradient calculation\n",
    "    def _get_gradient(self, X, y):\n",
    "        # get y difference\n",
    "        ydiff = y-self.predict_proba(X, add_intercept=False).ravel()\n",
    "        # make ydiff a column vector and multiply through\n",
    "        gradient = np.mean(X * ydiff[:, np.newaxis], axis=0)\n",
    "\n",
    "        return gradient.reshape(self.w_.shape)\n",
    "\n",
    "\n",
    "# use same params as defined above\n",
    "blr = VectorBinaryLogisticRegression(**params)\n",
    "blr.fit(X_train, y_train)\n",
    "print(blr.w_)\n",
    "yhat = blr.predict(X_test)\n",
    "print('Accuracy of Vectorized Programing for Regression: ', accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-versus-all to program a Multicalss Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained MultiClass Logistic Regression Object\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "\n",
    "    def __str__(self):\n",
    "        if (hasattr(self, 'w_')):\n",
    "            # is we have trained the object\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n' + str(self.w_)\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y)  # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = []  # will fill this array with binary classifiers\n",
    "\n",
    "        for i, yval in enumerate(self.unique_):  # for each unique value\n",
    "            y_binary = (y == yval)  # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,\n",
    "                                                 self.iters)\n",
    "            blr.fit(X, y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "\n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            # get probability for each classifier\n",
    "            probs.append(blr.predict_proba(X))\n",
    "\n",
    "        return np.hstack(probs)  # make into single matrix\n",
    "\n",
    "    def predict(self, X):\n",
    "        # take argmax along row\n",
    "        return self.unique_[np.argmax(self.predict_proba(X), axis=1)]\n",
    "\n",
    "\n",
    "lr = LogisticRegression(0.1, 1500)\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seren\\AppData\\Local\\Temp\\ipykernel_15296\\1043485029.py:17: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  gradient = np.mean(X * ydiff[:, np.newaxis], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[-0.01174409 -0.06053577  0.49916394  0.68773908 -0.32374941  0.24576778\n",
      "   0.11727782 -0.01352371 -0.20394337]\n",
      " [ 0.01174409  0.06053577 -0.49916394 -0.68773908  0.32374941 -0.24576778\n",
      "  -0.11727782  0.01352371  0.20394337]]\n",
      "Accuracy of:  0.8008363826450601\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train the MultiClass classifier with the optimal number of folds and the pca data\n",
    "for train_indices, test_indices in split_indices:\n",
    "    X_train, y_train = pca_feature[train_indices], labels[train_indices]\n",
    "    X_test, y_test = pca_feature[test_indices], labels[test_indices]\n",
    "\n",
    "\n",
    "# # train the MultiClass classifier with the pca data without the optimal number of folds\n",
    "# X = pca_feature\n",
    "# y = labels\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr)\n",
    "\n",
    "yhat = lr.predict(X_test)\n",
    "print('Accuracy of: ', accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. https://www.kaggle.com/datasets/kukuroo3/body-performance-data\n",
    "2. https://www.bigdata-culture.kr/bigdata/user/data_market/detail.do?id=ace0aea7-5eee-48b9-b616-637365d665c1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
